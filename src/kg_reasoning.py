"""
Knowledge Graph Reasoning
Stage 4: Graph ê¸°ë°˜ ì¶”ë¡  ë° Context ê²€ìƒ‰
"""

from neo4j import GraphDatabase
from typing import Dict, List, Optional
import re


class KGReasoner:
    """Knowledge Graph ì¶”ë¡  ì—”ì§„"""
    
    def __init__(self, uri: str = "bolt://localhost:7687", 
                 auth: tuple = ("neo4j", "password")):
        """
        Args:
            uri: Neo4j ì„œë²„ ì£¼ì†Œ
            auth: (username, password) íŠœí”Œ
        """
        try:
            self.driver = GraphDatabase.driver(uri, auth=auth)
            self.driver.verify_connectivity()
            print(f"âœ… Neo4j ì—°ê²° ì„±ê³µ: {uri}")
        except Exception as e:
            print(f"âŒ Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    def close(self):
        """ì—°ê²° ì¢…ë£Œ"""
        if self.driver:
            self.driver.close()
    
    def __enter__(self):
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        self.close()
    
    def _get_all_entity_names(self) -> List[str]:
        """Graphì— ìˆëŠ” ëª¨ë“  ì—”í‹°í‹° ì´ë¦„ ê°€ì ¸ì˜¤ê¸° (ìºì‹±ìš©)"""
        with self.driver.session() as session:
            result = session.run("MATCH (e:Entity) RETURN e.name as name")
            return [record["name"] for record in result]
    
    def extract_entities_from_text(self, text: str) -> List[str]:
        """
        ì§ˆë¬¸ì—ì„œ ì—”í‹°í‹° ì¶”ì¶œ (Graphì˜ ì‹¤ì œ ì—”í‹°í‹°ì™€ ë§¤ì¹­)
        
        Args:
            text: ì§ˆë¬¸ í…ìŠ¤íŠ¸
            
        Returns:
            Graphì— ì¡´ì¬í•˜ëŠ” ì—”í‹°í‹° ëª©ë¡
        """
        # ë¶ˆìš©ì–´ ë¦¬ìŠ¤íŠ¸ (ì¼ë°˜ì ì¸ ë‹¨ì–´, ì¡°ì‚¬ ë“±)
        stopwords = {
            # í•œê¸€ ì¡°ì‚¬ ë° ì ‘ë¯¸ì‚¬
            'ì´', 'ê°€', 'ì„', 'ë¥¼', 'ì€', 'ëŠ”', 'ì—', 'ì—ì„œ', 'ì™€', 'ê³¼', 'ì˜', 'ë¡œ', 'ìœ¼ë¡œ',
            'ë„', 'ë§Œ', 'ë¶€í„°', 'ê¹Œì§€', 'ì—ê²Œ', 'í•œí…Œ', 'ê»˜', 'ë³´ë‹¤', 'ì²˜ëŸ¼', 'ê°™ì´',
            # ì¼ë°˜ì ì¸ ë‹¨ì–´
            'ê²ƒ', 'ê±°', 'ìˆ˜', 'ë•Œ', 'ë“±', 'ì¤‘', 'ê°„', 'ë‚´', 'ì™¸', 'ìƒ', 'í•˜', 'ì „', 'í›„',
            'ê´€ê³„', 'ì´ìœ ', 'ë°©ë²•', 'íŠ¹ì§•', 'ì˜ë¯¸', 'ì •ì˜', 'ê°œë…', 'ì„¤ëª…', 'ë‚´ìš©',
            # ì§ˆë¬¸ ë‹¨ì–´
            'ë¬´ì—‡', 'ì–´ë””', 'ì–¸ì œ', 'ëˆ„êµ¬', 'ì–´ë–»ê²Œ', 'ì™œ', 'ì–´ë–¤', 'ë¬´ìŠ¨',
            # ì§§ì€ ë™ì‚¬/í˜•ìš©ì‚¬
            'í•˜ë‹¤', 'ë˜ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤', 'ì´ë‹¤', 'ì•„ë‹ˆë‹¤'
        }
        
        # Graphì˜ ëª¨ë“  ì—”í‹°í‹° ê°€ì ¸ì˜¤ê¸°
        all_entities = self._get_all_entity_names()
        
        # ì§ˆë¬¸ì— í¬í•¨ëœ ì—”í‹°í‹° ì°¾ê¸° (ëŒ€ì†Œë¬¸ì ë¬´ì‹œ)
        text_lower = text.lower()
        found_entities = []
        
        for entity in all_entities:
            if not entity or len(entity) < 2:  # ë„ˆë¬´ ì§§ì€ ì—”í‹°í‹° ì œì™¸
                continue
            
            entity_lower = entity.lower()
            
            # ë¶ˆìš©ì–´ ì œì™¸
            if entity_lower in stopwords:
                continue
            
            # ë‹¨ìˆœ í¬í•¨ì´ ì•„ë‹Œ, ë‹¨ì–´ ê²½ê³„ ê³ ë ¤
            if entity_lower in text_lower:
                # ê¸¸ì´ê°€ 2ê¸€ì ì´ìƒì´ê±°ë‚˜, ì˜ë¬¸/ìˆ«ìê°€ í¬í•¨ëœ ê²½ìš°ë§Œ
                if len(entity) >= 2 and (
                    len(entity) >= 3 or  # 3ê¸€ì ì´ìƒì€ ë¬´ì¡°ê±´ í¬í•¨
                    any(c.isalnum() and ord(c) < 128 for c in entity)  # ì˜ë¬¸/ìˆ«ì í¬í•¨
                ):
                    found_entities.append(entity)
        
        # ê¸¸ì´ìˆœìœ¼ë¡œ ì •ë ¬ (ê¸´ ì—”í‹°í‹° ìš°ì„  - "ë¨¸ì‹ ëŸ¬ë‹" > "ë¨¸ì‹ ")
        found_entities.sort(key=len, reverse=True)
        
        return found_entities[:10]  # ìµœëŒ€ 10ê°œ
    
    def find_entity_neighbors(self, entity_name: str, hops: int = 2) -> Dict:
        """
        ì—”í‹°í‹°ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ N-hop ì´ì›ƒ ì°¾ê¸°
        
        Graph RAGì˜ í•µì‹¬: ê´€ë ¨ëœ ì—”í‹°í‹°ë¥¼ ì°¾ì•„ì„œ Context êµ¬ì„±
        
        Args:
            entity_name: ê²€ìƒ‰í•  ì—”í‹°í‹° ì´ë¦„
            hops: íƒìƒ‰ ê¹Šì´ (ê¸°ë³¸ 2)
            
        Returns:
            entitiesì™€ relationships ë”•ì…”ë„ˆë¦¬
        """
        with self.driver.session() as session:
            # APOC ì—†ì´ êµ¬í˜„ (ìµœëŒ€ 2-hop)
            if hops == 1:
                query = """
                MATCH (e:Entity {name: $entity_name})-[r]-(related)
                RETURN e, related, r
                LIMIT 50
                """
            else:  # hops == 2 or more
                query = """
                MATCH path = (e:Entity {name: $entity_name})-[*1..2]-(related)
                WITH e, related, relationships(path) as rels
                RETURN DISTINCT e, related, rels
                LIMIT 50
                """
            
            result = session.run(query, entity_name=entity_name)
            
            entities = []
            relationships = []
            entity_ids = set()
            
            for record in result:
                # ì¤‘ì‹¬ ì—”í‹°í‹°
                if record["e"] and record["e"].element_id not in entity_ids:
                    entities.append(dict(record["e"]))
                    entity_ids.add(record["e"].element_id)
                
                # ê´€ë ¨ ì—”í‹°í‹°
                if record["related"] and record["related"].element_id not in entity_ids:
                    entities.append(dict(record["related"]))
                    entity_ids.add(record["related"].element_id)
                
                # ê´€ê³„
                if "rels" in record and record["rels"]:
                    for rel in record["rels"]:
                        relationships.append({
                            "type": rel.type,
                            "properties": dict(rel)
                        })
                elif "r" in record and record["r"]:
                    relationships.append({
                        "type": record["r"].type,
                        "properties": dict(record["r"])
                    })
            
            return {
                "entities": entities,
                "relationships": relationships
            }
    
    def semantic_path_search(self, start_entity: str, end_entity: str, 
                           max_depth: int = 5) -> List[Dict]:
        """
        ë‘ ì—”í‹°í‹° ê°„ì˜ ì˜ë¯¸ìˆëŠ” ê²½ë¡œ ì°¾ê¸°
        
        ì˜ˆ: "LLM" â†’ ... â†’ "Agentic Reasoning"
             ê°„ì— ì–´ë–¤ ê²½ë¡œë¡œ ì—°ê²°ë˜ì–´ ìˆë‚˜?
        
        Args:
            start_entity: ì‹œì‘ ì—”í‹°í‹°
            end_entity: ëª©í‘œ ì—”í‹°í‹°
            max_depth: ìµœëŒ€ ê²½ë¡œ ê¸¸ì´
            
        Returns:
            ê²½ë¡œ ë¦¬ìŠ¤íŠ¸
        """
        with self.driver.session() as session:
            query = f"""
            MATCH path = shortestPath(
                (start:Entity {{name: $start_entity}})-[*1..{max_depth}]-(end:Entity {{name: $end_entity}})
            )
            RETURN [node IN nodes(path) | node.name] as entity_path,
                   [rel IN relationships(path) | type(rel)] as relationship_types,
                   length(path) as path_length
            LIMIT 5
            """
            
            results = session.run(query, 
                                 start_entity=start_entity,
                                 end_entity=end_entity)
            
            paths = []
            for record in results:
                paths.append({
                    "entity_path": record["entity_path"],
                    "relationships": record["relationship_types"],
                    "length": record["path_length"]
                })
            
            return paths
    
    def find_related_notes(self, entity_name: str, top_k: int = 5) -> List[Dict]:
        """
        íŠ¹ì • ì—”í‹°í‹°ë¥¼ í¬í•¨í•˜ëŠ” Atomic Notes ì°¾ê¸°
        
        Args:
            entity_name: ì—”í‹°í‹° ì´ë¦„
            top_k: ë°˜í™˜í•  ìµœëŒ€ ë…¸íŠ¸ ìˆ˜
            
        Returns:
            ê´€ë ¨ ë…¸íŠ¸ ë¦¬ìŠ¤íŠ¸
        """
        with self.driver.session() as session:
            query = """
            MATCH (e:Entity {name: $entity_name})<-[:MENTIONS]-(n:AtomicNote)
            RETURN n.id as id, n.title as title, n.content as content, 
                   n.detailed_content as detailed_content,
                   n.domain as domain
            ORDER BY n.created_at DESC
            LIMIT $top_k
            """
            
            results = session.run(query, 
                                 entity_name=entity_name,
                                 top_k=top_k)
            
            notes = []
            for record in results:
                notes.append({
                    "id": record["id"],
                    "title": record["title"],
                    "content": record["content"],
                    "detailed_content": record.get("detailed_content", ""),
                    "domain": record.get("domain", "general")
                })
            
            return notes
    
    def find_similar_entities(self, entity_name: str, top_k: int = 10) -> List[Dict]:
        """
        ìœ ì‚¬í•œ ì—”í‹°í‹° ì°¾ê¸° (ê°™ì€ ë„ë©”ì¸, ë¹„ìŠ·í•œ ê´€ê³„ íŒ¨í„´)
        
        Args:
            entity_name: ê¸°ì¤€ ì—”í‹°í‹°
            top_k: ë°˜í™˜í•  ìµœëŒ€ ì—”í‹°í‹° ìˆ˜
            
        Returns:
            ìœ ì‚¬ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
        """
        with self.driver.session() as session:
            query = """
            MATCH (e1:Entity {name: $entity_name})
            MATCH (e2:Entity)
            WHERE e2.name <> $entity_name 
              AND e2.domain = e1.domain
            WITH e2, COUNT { (e2)-[]->() } as out_degree,
                     COUNT { (e2)<-[]-() } as in_degree
            RETURN e2.name as name, e2.domain as domain, 
                   out_degree + in_degree as connections
            ORDER BY connections DESC
            LIMIT $top_k
            """
            
            results = session.run(query, entity_name=entity_name, top_k=top_k)
            
            similar = []
            for record in results:
                similar.append({
                    "name": record["name"],
                    "domain": record["domain"],
                    "connections": record["connections"]
                })
            
            return similar
    
    def reasoning_chain(self, question: str, depth: int = 2) -> Dict:
        """
        ì§ˆë¬¸ â†’ ì—”í‹°í‹° ì¶”ì¶œ â†’ Graph íƒìƒ‰ â†’ Context êµ¬ì„±
        
        Graph RAGì˜ í•µì‹¬ ì›Œí¬í”Œë¡œìš°
        
        Args:
            question: ì‚¬ìš©ì ì§ˆë¬¸
            depth: íƒìƒ‰ ê¹Šì´
            
        Returns:
            ì¶”ë¡  ê²°ê³¼ (ì—”í‹°í‹°, ë…¸íŠ¸, ê²½ë¡œ ë“±)
        """
        print(f"\nğŸ” ì§ˆë¬¸ ë¶„ì„: {question}")
        
        # 1. ì§ˆë¬¸ì—ì„œ ì£¼ìš” ì—”í‹°í‹° ì¶”ì¶œ (Graphì— ìˆëŠ” ê²ƒë§Œ)
        existing_entities = self.extract_entities_from_text(question)
        print(f"âœ… Graphì—ì„œ ë°œê²¬ëœ ì—”í‹°í‹°: {existing_entities[:5]}")
        
        if not existing_entities:
            return {
                "question": question,
                "entities": [],
                "entity_contexts": [],
                "related_notes": [],
                "connecting_paths": [],
                "message": "ì§ˆë¬¸ì—ì„œ Graphì— ì¡´ì¬í•˜ëŠ” ì—”í‹°í‹°ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."
            }
        
        # 3. ê° ì—”í‹°í‹°ì˜ ì´ì›ƒ ì°¾ê¸°
        all_context = []
        all_notes = []
        
        for entity in existing_entities[:3]:  # ìµœëŒ€ 3ê°œ ì—”í‹°í‹°
            print(f"\n  ğŸ“Š '{entity}' ì£¼ë³€ íƒìƒ‰ ì¤‘...")
            
            neighbors = self.find_entity_neighbors(entity, hops=depth)
            related_notes = self.find_related_notes(entity, top_k=3)
            
            all_context.append({
                "entity": entity,
                "neighbors": neighbors,
                "related_notes_count": len(related_notes)
            })
            
            all_notes.extend(related_notes)
            print(f"     - ì—°ê²°ëœ ì—”í‹°í‹°: {len(neighbors['entities'])}ê°œ")
            print(f"     - ê´€ë ¨ ë…¸íŠ¸: {len(related_notes)}ê°œ")
        
        # 4. ì—”í‹°í‹° ê°„ ê²½ë¡œ ì°¾ê¸°
        paths = []
        if len(existing_entities) >= 2:
            print(f"\n  ğŸ”— ì—”í‹°í‹° ê°„ ê²½ë¡œ íƒìƒ‰...")
            for i in range(min(2, len(existing_entities) - 1)):
                for j in range(i + 1, min(i + 2, len(existing_entities))):
                    e1, e2 = existing_entities[i], existing_entities[j]
                    path = self.semantic_path_search(e1, e2, max_depth=4)
                    if path:
                        paths.extend(path)
                        print(f"     - {e1} â†” {e2}: {len(path)}ê°œ ê²½ë¡œ ë°œê²¬")
        
        return {
            "question": question,
            "entities": existing_entities,
            "entity_contexts": all_context,
            "related_notes": all_notes,
            "connecting_paths": paths
        }
    
    def entity_exists(self, entity_name: str) -> bool:
        """ì—”í‹°í‹°ê°€ Graphì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸"""
        with self.driver.session() as session:
            query = "MATCH (e:Entity {name: $name}) RETURN count(e) > 0 as exists"
            result = session.run(query, name=entity_name).single()
            return result["exists"] if result else False
    
    def get_entity_summary(self, entity_name: str) -> Dict:
        """ì—”í‹°í‹° ìš”ì•½ ì •ë³´"""
        with self.driver.session() as session:
            query = """
            MATCH (e:Entity {name: $name})
            OPTIONAL MATCH (e)-[r]-()
            OPTIONAL MATCH (e)<-[:MENTIONS]-(n:AtomicNote)
            RETURN e.name as name, 
                   e.domain as domain,
                   e.label as label,
                   COUNT(DISTINCT r) as total_relationships,
                   COUNT(DISTINCT n) as mentioned_in_notes
            """
            
            result = session.run(query, name=entity_name).single()
            
            if result:
                return {
                    "name": result["name"],
                    "domain": result["domain"],
                    "label": result["label"],
                    "relationships": result["total_relationships"],
                    "notes": result["mentioned_in_notes"]
                }
            return {}


def create_graph_context_for_llm(reasoning_result: Dict, max_tokens: int = 2000) -> str:
    """
    Graph ì¶”ë¡  ê²°ê³¼ë¥¼ LLMì— ìµœì í™”ëœ Contextë¡œ ë³€í™˜
    
    Traditional RAG: ê¸´ ë¬¸ì„œ ì²­í¬ â†’ í† í° ë‚­ë¹„
    Graph RAG: ì§ì ‘ ê´€ë ¨ëœ ì—”í‹°í‹°ì™€ ê´€ê³„ë§Œ â†’ íš¨ìœ¨ì 
    
    Args:
        reasoning_result: reasoning_chainì˜ ê²°ê³¼
        max_tokens: ìµœëŒ€ í† í° ìˆ˜ (ëŒ€ëµì )
        
    Returns:
        LLMì— ì œê³µí•  ì»¨í…ìŠ¤íŠ¸ ë¬¸ìì—´
    """
    context = f"""## ğŸ” ì§ˆë¬¸ ë¶„ì„
ì§ˆë¬¸: {reasoning_result['question']}
ì¶”ì¶œëœ í•µì‹¬ ê°œë…: {', '.join(reasoning_result['entities'])}

## ğŸ“Š ê´€ë ¨ ì§€ì‹ ê·¸ë˜í”„

"""
    
    # ì—”í‹°í‹°ë³„ ì»¨í…ìŠ¤íŠ¸
    for entity_ctx in reasoning_result['entity_contexts']:
        context += f"\n### {entity_ctx['entity']}\n"
        
        neighbors = entity_ctx['neighbors']
        if neighbors['entities']:
            entity_names = [e.get('name', str(e)) for e in neighbors['entities'][:5]]
            context += f"ê´€ë ¨ ê°œë…: {', '.join(entity_names)}\n"
        
        if entity_ctx['related_notes_count'] > 0:
            context += f"ê´€ë ¨ ë…¸íŠ¸: {entity_ctx['related_notes_count']}ê°œ\n"
    
    # ì—°ê²° ê²½ë¡œ
    if reasoning_result['connecting_paths']:
        context += "\n### ê°œë… ê°„ ì—°ê²° ê²½ë¡œ\n"
        for i, path in enumerate(reasoning_result['connecting_paths'][:3], 1):
            # None ê°’ í•„í„°ë§
            entity_path = [str(e) for e in path['entity_path'] if e is not None]
            if entity_path:
                path_str = " â†’ ".join(entity_path)
                context += f"{i}. {path_str}\n"
    
    # ê´€ë ¨ ë…¸íŠ¸ ë‚´ìš©
    if reasoning_result['related_notes']:
        context += "\n## ğŸ“ ê´€ë ¨ ë…¸íŠ¸ ë‚´ìš©\n"
        for i, note in enumerate(reasoning_result['related_notes'][:5], 1):
            context += f"\n### {i}. {note['title']}\n"
            context += f"{note['content'][:200]}...\n"
    
    # í† í° ì œí•œ (ëŒ€ëµ 1 token â‰ˆ 4 characters)
    if len(context) > max_tokens * 4:
        context = context[:max_tokens * 4] + "\n\n... (ì»¨í…ìŠ¤íŠ¸ê°€ ì˜ë ¸ìŠµë‹ˆë‹¤)"
    
    return context


# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == "__main__":
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    # í™˜ê²½ë³€ìˆ˜ì—ì„œ Neo4j ì„¤ì • ê°€ì ¸ì˜¤ê¸°
    NEO4J_URI = os.getenv("NEO4J_URI", "bolt://localhost:7687")
    NEO4J_USER = os.getenv("NEO4J_USER", "neo4j")
    NEO4J_PASSWORD = os.getenv("NEO4J_PASSWORD", "password")
    
    print("ğŸ”¬ Knowledge Graph Reasoning í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    try:
        with KGReasoner(NEO4J_URI, (NEO4J_USER, NEO4J_PASSWORD)) as reasoner:
            # í…ŒìŠ¤íŠ¸ ì§ˆë¬¸
            test_questions = [
                "AIì™€ ë¨¸ì‹ ëŸ¬ë‹ì˜ ê´€ê³„ëŠ”?",
                "ìŠ¤íƒ€íŠ¸ì—…ì—ì„œ ë„¤íŠ¸ì›Œí‚¹ì´ ì¤‘ìš”í•œ ì´ìœ ëŠ”?",
                "PKM ì‹œìŠ¤í…œì€ ì–´ë–»ê²Œ ì‘ë™í•˜ë‚˜?"
            ]
            
            for question in test_questions:
                print(f"\n{'=' * 60}")
                result = reasoner.reasoning_chain(question, depth=2)
                
                print(f"\nğŸ“‹ ì¶”ë¡  ê²°ê³¼:")
                print(f"  - ë°œê²¬ëœ ì—”í‹°í‹°: {len(result['entities'])}ê°œ")
                print(f"  - ê´€ë ¨ ë…¸íŠ¸: {len(result['related_notes'])}ê°œ")
                print(f"  - ì—°ê²° ê²½ë¡œ: {len(result['connecting_paths'])}ê°œ")
                
                # LLM Context ìƒì„±
                context = create_graph_context_for_llm(result, max_tokens=500)
                print(f"\nğŸ’¬ LLM Context (ì²˜ìŒ 300ì):")
                print(context[:300] + "...")
            
            print("\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬: {e}")
        import traceback
        traceback.print_exc()

