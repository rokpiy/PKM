"""
Entity & Relationship Extraction (Simple Version)
Gemini API ê²°ê³¼ + Regex íŒ¨í„´ ë§¤ì¹­ ê¸°ë°˜
spaCy ì—†ì´ ë™ìž‘í•˜ëŠ” ê²½ëŸ‰ ë²„ì „
"""

import re
import json
from typing import List, Dict


class SimpleEntityExtractor:
    """ê°„ë‹¨í•œ ì—”í‹°í‹°ì™€ ê´€ê³„ ì¶”ì¶œê¸° (Gemini ê²°ê³¼ ê¸°ë°˜)"""
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        print("âœ… Simple Entity Extractor ì´ˆê¸°í™” ì™„ë£Œ")
    
    def enhance_gemini_entities(self, atomic_note: Dict) -> Dict:
        """
        Geminiê°€ ì¶”ì¶œí•œ ì—”í‹°í‹°ë¥¼ ê°œì„ í•˜ê³  ì¶”ê°€ ê´€ê³„ ì¶”ì¶œ
        
        Args:
            atomic_note: Atomic Note (Geminiì˜ extracted_entities í¬í•¨)
            
        Returns:
            ê°œì„ ëœ Atomic Note
        """
        # Geminiê°€ ì´ë¯¸ ì¶”ì¶œí•œ ì—”í‹°í‹° ê°€ì ¸ì˜¤ê¸°
        gemini_entities = atomic_note.get("extracted_entities", [])
        
        # í…ìŠ¤íŠ¸ì—ì„œ ì¶”ê°€ ì—”í‹°í‹° ì¶”ì¶œ
        content = atomic_note.get("content", "")
        detailed_content = atomic_note.get("detailed_content", "")
        full_text = f"{content} {detailed_content}"
        
        # ì¶”ê°€ ì—”í‹°í‹° ì¶”ì¶œ (ê°„ë‹¨í•œ íŒ¨í„´ ê¸°ë°˜)
        additional_entities = self._extract_additional_entities(full_text)
        
        # ì¤‘ë³µ ì œê±°
        all_entities = gemini_entities + additional_entities
        unique_entities = self._deduplicate_entities(all_entities)
        
        # ê´€ê³„ ì¶”ì¶œ
        gemini_relationships = atomic_note.get("relationships", [])
        additional_relationships = self.extract_relationships(full_text, unique_entities)
        
        # ê²°ê³¼ ì €ìž¥
        atomic_note["entities_enhanced"] = unique_entities
        atomic_note["relationships_enhanced"] = gemini_relationships + additional_relationships
        
        return atomic_note
    
    def _extract_additional_entities(self, text: str) -> List[str]:
        """
        ê°„ë‹¨í•œ íŒ¨í„´ìœ¼ë¡œ ì¶”ê°€ ì—”í‹°í‹° ì¶”ì¶œ
        """
        entities = []
        
        # ëŒ€ë¬¸ìžë¡œ ì‹œìž‘í•˜ëŠ” ë‹¨ì–´ (ê³ ìœ ëª…ì‚¬ ì¶”ì •)
        proper_nouns = re.findall(r'\b[A-Z][a-z]+(?:\s+[A-Z][a-z]+)*\b', text)
        entities.extend(proper_nouns)
        
        # í•œê¸€ ê³ ìœ ëª…ì‚¬ íŒ¨í„´ (ì¡°ì‚¬ ì•žì˜ ëª…ì‚¬)
        korean_nouns = re.findall(r'([ê°€-íž£]+)(?:ì´|ê°€|ì€|ëŠ”|ì„|ë¥¼|ì˜|ì—|ì™€|ê³¼)', text)
        entities.extend(korean_nouns)
        
        # ê¸°ìˆ  ìš©ì–´ íŒ¨í„´ (ëŒ€ë¬¸ìž ì•½ì–´)
        acronyms = re.findall(r'\b[A-Z]{2,}\b', text)
        entities.extend(acronyms)
        
        return list(set(entities))  # ì¤‘ë³µ ì œê±°
    
    def _deduplicate_entities(self, entities: List[str]) -> List[str]:
        """ì—”í‹°í‹° ì¤‘ë³µ ì œê±° (ëŒ€ì†Œë¬¸ìž ë¬´ì‹œ)"""
        seen = set()
        unique = []
        
        for entity in entities:
            entity_lower = entity.lower()
            if entity_lower not in seen:
                seen.add(entity_lower)
                unique.append(entity)
        
        return unique
    
    def extract_relationships(self, text: str, entities: List[str]) -> List[Dict]:
        """
        ì—”í‹°í‹° ê°„ ê´€ê³„ ì¶”ì¶œ (íŒ¨í„´ ê¸°ë°˜)
        
        Args:
            text: ì›ë³¸ í…ìŠ¤íŠ¸
            entities: ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê´€ê³„ ë¦¬ìŠ¤íŠ¸
        """
        relationships = []
        
        # í•œê¸€ ê´€ê³„ íŒ¨í„´
        korean_patterns = {
            "supports": [
                r"({})(?:ì´|ê°€)\s+({})(?:ì„|ë¥¼)\s+ì§€ì§€",
                r"({})(?:ì€|ëŠ”)\s+({})(?:ì„|ë¥¼)\s+ì˜¹í˜¸"
            ],
            "contradicts": [
                r"({})(?:ì´|ê°€)\s+({})(?:ì™€|ê³¼)\s+ëª¨ìˆœ",
                r"({})(?:ì€|ëŠ”)\s+({})(?:ì™€|ê³¼)\s+ë°˜ëŒ€"
            ],
            "is_example_of": [
                r"({})(?:ì€|ëŠ”)\s+({})ì˜\s+ì˜ˆì‹œ",
                r"({})(?:ì€|ëŠ”)\s+({})ì˜\s+ì‚¬ë¡€"
            ],
            "causes": [
                r"({})(?:ì´|ê°€)\s+({})(?:ì„|ë¥¼)\s+ì•¼ê¸°",
                r"({})(?:ì€|ëŠ”)\s+({})(?:ì„|ë¥¼)\s+ì´ˆëž˜"
            ],
            "implements": [
                r"({})(?:ì´|ê°€)\s+({})(?:ì„|ë¥¼)\s+êµ¬í˜„",
                r"({})(?:ì€|ëŠ”)\s+({})(?:ì„|ë¥¼)\s+ì‹¤í˜„"
            ],
            "uses": [
                r"({})(?:ì´|ê°€)\s+({})(?:ì„|ë¥¼)\s+ì‚¬ìš©",
                r"({})(?:ì€|ëŠ”)\s+({})(?:ì„|ë¥¼)\s+í™œìš©"
            ],
            "based_on": [
                r"({})(?:ì€|ëŠ”)\s+({})ì—?\s+ê¸°ë°˜",
                r"({})(?:ì€|ëŠ”)\s+({})ë¥¼?\s+ë°”íƒ•"
            ]
        }
        
        # ì˜ë¬¸ ê´€ê³„ íŒ¨í„´
        english_patterns = {
            "supports": [r"({}) supports? ({})"],
            "contradicts": [r"({}) contradicts? ({})"],
            "is_example_of": [r"({}) is an? example of ({})"],
            "causes": [r"({}) causes? ({})"],
            "implements": [r"({}) implements? ({})"],
            "uses": [r"({}) uses? ({})"],
            "based_on": [r"({}) is based on ({})"]
        }
        
        # ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¥¼ regex íŒ¨í„´ìœ¼ë¡œ ë³€í™˜
        entity_pattern = "|".join(re.escape(e) for e in entities)
        
        # ëª¨ë“  íŒ¨í„´ ì ìš©
        all_patterns = {**korean_patterns, **english_patterns}
        
        for relation_type, patterns in all_patterns.items():
            for pattern_template in patterns:
                # ì—”í‹°í‹° ìœ„ì¹˜ì— ì‹¤ì œ ì—”í‹°í‹° íŒ¨í„´ ì‚½ìž…
                pattern = pattern_template.format(entity_pattern, entity_pattern)
                
                try:
                    matches = re.finditer(pattern, text, re.IGNORECASE)
                    for match in matches:
                        relationships.append({
                            "from": match.group(1).strip(),
                            "type": relation_type,
                            "to": match.group(2).strip(),
                            "confidence": 0.7,
                            "method": "pattern_matching"
                        })
                except:
                    pass  # íŒ¨í„´ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return relationships
    
    def process_atomic_notes_batch(self, atomic_notes_results: List[Dict]) -> List[Dict]:
        """
        ì—¬ëŸ¬ Atomic Notes ë°°ì¹˜ ì²˜ë¦¬
        
        Args:
            atomic_notes_results: Geminiì˜ Atomic Notes ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ê°œì„ ëœ Atomic Notes ë¦¬ìŠ¤íŠ¸
        """
        enhanced_results = []
        
        for result in atomic_notes_results:
            atomic_notes = result.get("atomic_notes", [])
            
            for note in atomic_notes:
                enhanced_note = self.enhance_gemini_entities(note)
                
            result["atomic_notes"] = atomic_notes
            enhanced_results.append(result)
        
        return enhanced_results


# CLI ì¸í„°íŽ˜ì´ìŠ¤
if __name__ == "__main__":
    print("ðŸ”¬ Simple Entity Extraction í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # í…ŒìŠ¤íŠ¸ìš© Atomic Note (Gemini ê²°ê³¼ ì‹œë®¬ë ˆì´ì…˜)
    sample_note = {
        "id": "note_test_001",
        "title": "AIì™€ ë¨¸ì‹ ëŸ¬ë‹",
        "content": "ì¸ê³µì§€ëŠ¥(AI)ì€ ë¨¸ì‹ ëŸ¬ë‹ì„ ì‚¬ìš©í•˜ì—¬ ë¬¸ì œë¥¼ í•´ê²°í•©ë‹ˆë‹¤.",
        "detailed_content": "ë”¥ëŸ¬ë‹ì€ ë¨¸ì‹ ëŸ¬ë‹ì˜ í•œ ì˜ˆì‹œìž…ë‹ˆë‹¤. êµ¬ê¸€ê³¼ ì˜¤í”ˆAIëŠ” AI ì—°êµ¬ë¥¼ ì„ ë„í•©ë‹ˆë‹¤.",
        "extracted_entities": ["AI", "ë¨¸ì‹ ëŸ¬ë‹", "ë”¥ëŸ¬ë‹"],
        "relationships": [
            {"from": "AI", "type": "uses", "to": "ë¨¸ì‹ ëŸ¬ë‹"}
        ]
    }
    
    # Extractor ì´ˆê¸°í™”
    extractor = SimpleEntityExtractor()
    
    # ê°œì„ 
    enhanced_note = extractor.enhance_gemini_entities(sample_note)
    
    print(f"\nðŸ“ ì›ë³¸ ì—”í‹°í‹°: {sample_note['extracted_entities']}")
    print(f"âœ… ê°œì„ ëœ ì—”í‹°í‹°: {enhanced_note.get('entities_enhanced', [])}")
    
    print(f"\nðŸ“ ì›ë³¸ ê´€ê³„: {len(sample_note['relationships'])}ê°œ")
    print(f"âœ… ê°œì„ ëœ ê´€ê³„: {len(enhanced_note.get('relationships_enhanced', []))}ê°œ")
    
    for i, rel in enumerate(enhanced_note.get('relationships_enhanced', [])[:5], 1):
        print(f"  [{i}] {rel['from']:15s} --[{rel['type']}]--> {rel['to']:15s}")
    
    print("\n" + "=" * 60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")

